<!DOCTYPE HTML>

<html>
    <head>
      
     <br>
      
      <div class="js-toggle-wrapper">
  <div class="js-toggle">
    <div class="js-toggle-track">
      <div class="js-toggle-track-check">
        <img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16">
          </div>
          <div class="js-toggle-track-x">
            <img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16">
              </div>
              </div>
              <div class="js-toggle-thumb"></div>
                <input class="js-toggle-screenreader-only" type="checkbox" aria-label="Switch between Dark and Light mode">
                  </div>
                  </div>
  
  <style>

 

.js-toggle-wrapper {
    display: table;
    margin: 0 auto;
}

.js-toggle {
    touch-action: pan-x;
    display: inline-block;
    position: relative;
    cursor: pointer;
    background-color: transparent;
    border: 0;
    padding: 0;
    -webkit-touch-callout: none;
    user-select: none;
    -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    -webkit-tap-highlight-color: transparent;
  }
  
  .js-toggle-screenreader-only {
    border: 0;
    clip: rect(0 0 0 0);
    height: 1px;
    margin: -1px;
    overflow: hidden;
    padding: 0;
    position: absolute;
    width: 1px;
  }
  
  .js-toggle-track {
    width: 50px;
    height: 24px;
    padding: 0;
    border-radius: 30px;
    background-color: hsl(222, 14%, 7%);
    transition: all 0.2s ease;
  }
  
  .js-toggle-track-check {
    position: absolute;
    width: 17px;
    height: 17px;
    left: 5px;
    top: 0px;
    bottom: 0px;
    margin-top: auto;
    margin-bottom: auto;
    line-height: 0;
    opacity: 0;
    transition: opacity 0.25s ease;
  }
  
  .js-toggle--checked .js-toggle-track-check {
    opacity: 1;
    transition: opacity 0.25s ease;
  }
  
  .js-toggle-track-x {
    position: absolute;
    width: 17px;
    height: 17px;
    right: 5px;
    top: 0px;
    bottom: 0px;
    margin-top: auto;
    margin-bottom: auto;
    line-height: 0;
    opacity: 1;
    transition: opacity 0.25s ease;
  }
  
  .js-toggle--checked .js-toggle-track-x {
    opacity: 0;
  }
  
  .js-toggle-thumb {
    position: absolute;
    top: 1px;
    left: 1px;
    width: 22px;
    height: 22px;
    border-radius: 50%;
    background-color: #fafafa;
    box-sizing: border-box;
    transition: all 0.5s cubic-bezier(0.23, 1, 0.32, 1) 0ms;
    transform: translateX(0);
  }
  
  .js-toggle--checked .js-toggle-thumb {
    transform: translateX(26px);
    border-color: #19ab27;
  }
  
  .js-toggle--focus .js-toggle-thumb {
    box-shadow: 0px 0px 2px 3px rgb(255, 167, 196);
  }
  
  .js-toggle:active .js-toggle-thumb {
    box-shadow: 0px 0px 5px 5px rgb(255, 167, 196);
  }
  
  body.dark-mode , 
  body.dark-mode main * {
    background-color: #000000;
    color: #000000;
    filter: invert(0.95);
}

  .dark-mode img {
  filter: invert(1) contrast(1.3) saturate(1.4);
}

  .dark-mode p {
  color: #000000;
}
  
  .dark-mode code {
    filter: invert(1) contrast(1.3) saturate(1.4);
    font-weight: bold;
    background: #353737;
    color: white;
}

  .dark-mode strong, b {
    filter: invert(1) contrast(1.3) saturate(1.4);
  }
  
  .dark-mode #social-share ul{
    margin: 0;
    filter: invert(1) contrast(1.3) saturate(1.4);
  }

  .dark-mode #header {
    filter: invert(1) contrast(1.3) saturate(1.4);
    position: fixed;
  }

  .dark-mode .js-toggle--focus .js-toggle-thumb {
    filter: invert(1) contrast(1.3) saturate(1.4);
  }

  .dark-mode .footer {
    filter: invert(1) contrast(1.3) saturate(1.4);
    position: fixed;
    background-color: white;
    font-weight: bold;
  }

  .dark-mode .nav-secondary {
    filter: invert(1) contrast(1.3) saturate(1.4);
}

  .dark-mode #reactions .reaction-items .reaction-item .reaction-item__button img, #reactions-promotion .reaction-items .reaction-item .reaction-item__button img {
    filter: invert(1) contrast(1.3) saturate(1.4);
}

</style>

<script>
    var body = document.body;
    var article = document.article;
	var switcher = document.getElementsByClassName('js-toggle')[0];

	
	switcher.addEventListener("click", function() {
        this.classList.toggle('js-toggle--checked');
        this.classList.add('js-toggle--focus');
		
		if (this.classList.contains('js-toggle--checked')) {
			body.classList.add('dark-mode');
			article.classList.add('post.dark-mode');
			
			localStorage.setItem('darkMode', 'true');
		} else {
			body.classList.remove('dark-mode');
			article.classList.remove('post.dark-mode');
			setTimeout(function() {
				localStorage.removeItem('darkMode');
			}, 100);
		}
	})

	
	if (localStorage.getItem('darkMode')) {
		
        switcher.classList.add('js-toggle--checked');
        body.classList.add('dark-mode');
        article.classList.add('post.dark-mode');
	}

</script>


      
        <script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "https:\/\/algotech.netlify.com\/"
        },
        "articleSection" : "blog",
        "name" : "Song2Vec: Music Recommender",
        "headline" : "Song2Vec: Music Recommender",
        "description" : "body { text-align: justify}  Background The behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music, Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically.",
        "inLanguage" : "en",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2020",
        "datePublished": "2020-06-29 00:00:00 \u002b0000 UTC",
        "dateModified" : "2020-06-29 00:00:00 \u002b0000 UTC",
        "url" : "https:\/\/algotech.netlify.com\/blog\/song2vec-music-recommender\/",
        "wordCount" : "4955",
        "keywords" : [ "Machine Learning","Topic Modelling","Recommender System","gensim","Blog" ]
    }
    </script>
        
            
                <title>Song2Vec: Music Recommender</title>
            
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="generator" content="Hugo 0.87.0" />
        
  
    
  

  

  <link rel="apple-touch-icon-precomposed" href='https://algotech.netlify.com/favicon/apple-touch-icon-precomposed.png'>
  <link rel="icon" href='https://algotech.netlify.com/favicon/favicon.png'>
  
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content='/favicon/mstile.png'>
  <meta name="application-name" content="Algoritma Technical Blog">
  <meta name="msapplication-tooltip" content="To learn more about our approach to data science problems, feel free to hop over to our blog.">
  <meta name="msapplication-config" content='/favicon/ieconfig.xml'>



        
            <meta name="author" content="Tomy Tjandra">
        
        
            
                <meta name="description" content="To learn more about our approach to data science problems, feel free to hop over to our blog.">
            
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Song2Vec: Music Recommender"/>
<meta name="twitter:description" content="body { text-align: justify}  Background The behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music, Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically."/>
<meta name="twitter:site" content="@teamalgoritma"/>

        <meta property="og:title" content="Song2Vec: Music Recommender" />
<meta property="og:description" content="body { text-align: justify}  Background The behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music, Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://algotech.netlify.com/blog/song2vec-music-recommender/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2020-06-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-29T00:00:00+00:00" />


        <meta property="og:image" content="https://algotech.netlify.com//images/logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="512">
        <meta property="og:image:height" content="512">
        <meta itemprop="name" content="Song2Vec: Music Recommender">
<meta itemprop="description" content="body { text-align: justify}  Background The behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music, Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically."><meta itemprop="datePublished" content="2020-06-29T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-06-29T00:00:00+00:00" />
<meta itemprop="wordCount" content="4955">
<meta itemprop="keywords" content="Machine Learning,Topic Modelling,Recommender System,gensim," />
        

        
            
        

        
        
            <link disabled id="dark-mode-theme" rel="stylesheet" href="https://algotech.netlify.com/css/dark.css">
            <link rel="stylesheet" href="https://algotech.netlify.com/css/monokai-sublime.css">
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
            <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.css">
            <link rel="stylesheet" href="https://algotech.netlify.com/css/main.css">
            <link rel="stylesheet" href="https://algotech.netlify.com/css/add-on.css">
            <link rel="stylesheet" href="https://algotech.netlify.com/css/academicons.min.css">
            <link href="https://algotech.netlify.com/lib/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
            <link href="https://algotech.netlify.com/lib/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet">
            <link href="https://algotech.netlify.com/lib/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet">
            <link href="https://algotech.netlify.com/lib/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet">
        
            <link rel="stylesheet" href=
            "https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
                <link rel="stylesheet" href=
            "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
                      integrity=
            "sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" 
                      crossorigin="anonymous">
                <script src=
            "https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js">
                </script>
                <script src=
            "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js">
                </script>
                <script src="https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.1.0/js.cookie.js">
                </script>
                
                <script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.0/jquery.cookie.min.js">
                </script>
              
                <style>
                    
                     


                    .modal:before {
                        content: '';
                        display: inline-block;
                        height: 20%;
                        vertical-align: middle;
                    }
                      
                    .modal-dialog {
                        
                    display: -webkit-box;
                    display: -webkit-flex;
                    display: -ms-flexbox;
                    display: flex;
                    -webkit-box-orient: vertical;
                    -webkit-box-direction: normal;
                    -webkit-flex-direction: column;
                        -ms-flex-direction: column;
                            flex-direction: column;
                    -webkit-box-pack: center;
                    -webkit-justify-content: center;
                        -ms-flex-pack: center;
                            justify-content: center;
                    }

                      
                    .modal .modal-content {
                        padding: 20px 20px 20px 20px;
                        -webkit-animation-name: modal-animation;
                        -webkit-animation-duration: 0.5s;
                        animation-name: modal-animation;
                        animation-duration: 1.5s;
                    }

                

                    .modal .leadin-button {
                        -webkit-border-radius: 0.25em;
                        -moz-border-radius: 0.25em;
                        -ms-border-radius: 0.25em;
                        -o-border-radius: 0.25em;
                        border-radius: 0.25em;
                        -webkit-appearance: none;
                        cursor: pointer;
                        font-size: 1em;
                        font-weight: bold;
                        line-height: 1;
                        padding: 1em 1.5em;
                        width: 100%;
                        text-decoration: none;
                    }
                    .modal .leadin-button-primary {
                        background: #a90606 !important;
                        color: #FFFFFF !important;
                    }
                      
                    @-webkit-keyframes modal-animation {
                        from {
                            top: -100px;
                            opacity: 0;
                        }
                        to {
                            top: 0px;
                            opacity: 1;
                        }
                    }
                      
                    @keyframes modal-animation {
                        from {
                            top: -100px;
                            opacity: 0;
                        }
                        to {
                            top: 0px;
                            opacity: 1;
                        }
                    }
                </style>

            <script src="content/bootstrapJS/jquery-2.1.1.min.js" type="text/javascript"></script>

            <script type="text/javascript">
                
                
                $( document ).ready(function() {
  if (document.cookie.indexOf('visited=true') == -1){
    
                      $('#signupModal').modal('show');
    
                  var year = 1000*60*60*24*365;
    var expires = new Date((new Date()).valueOf() + year);
    document.cookie = "visited=true;expires=" + expires.toUTCString();

  }
}); 

            </script>
        
            

        
            
                
            
                
                    <link rel="stylesheet" href="https://algotech.netlify.com/css/main.css">
                
            
        


  
    
      <link rel="stylesheet" href="https://algotech.netlify.com/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
      <script src="https://algotech.netlify.com/js/highlight.pack.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>
  


      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-164959107-2', 'auto');
	
	ga('send', 'pageview');
}
</script>



      
    </head>
    <body>

        <div class="modal" id="signupModal"
        role="dialog" aria-labelledby="myModalLabel"
        aria-hidden="true">
 
       <div class="modal-dialog">
           <div class="modal-content">
 
               
               <div class="m-header">
                   <button class="close" data-dismiss="modal">
                       ×
                   </button>
                   <h2 class="myModalLabel"> Upcoming Workshop! </h2>
               </div>
 
               
               <div class="inputs">
 
                <a href="https://algorit.ma/ds-course/hr-industry/?utm_source=algotech"><img src="https://algotech.netlify.com/img/2021/ads/ks-hr.png",
                     alt="Building Tools for the HR Industry", style="float: left; padding-right: 20px;" padding: 1px  width="30%" height="30%"></a>
                <p>In this Kickstart Series, serial software entrepreneur Samuel Chan helps us get a behind-the-scenes look at how data scientists and developers create systems that bring the best out of the HR function.In this Kickstart Series, serial software entrepreneur Samuel Chan helps us get a behind-the-scenes look at how data scientists and developers create systems that bring the best out of the HR function.</p>
                <div class="advance-wrapper callout-special-font">
                    <a href="https://algorit.ma/ds-course/hr-industry/?utm_source=algotech" target="_blank" 
                    class="leadin-button leadin-advance-button leadin-button-primary">LEARN MORE</a>
                </div>
               </div>
 
 
           </div>
       </div>
   </div>

    </body>

      
      <div id="wrapper">

    
    
<header id="header">
    
      <h1><a href="https://algotech.netlify.com/">blog</a></h1>
    

    <nav class="links">
        <ul>
            
                <li>
                    <a href="https://algotech.netlify.com/">
                            <i class="fa fa-home">&nbsp;</i>Home
                    </a>
                </li>
            
                <li>
                    <a href="https://algotech.netlify.com/tags/machine-learning/">
                            <i class="fa fa-cog">&nbsp;</i>Machine Learning
                    </a>
                </li>
            
                <li>
                    <a href="https://algotech.netlify.com/tags/data-visualization/">
                            <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                    </a>
                </li>
            
                <li>
                    <a href="https://algotech.netlify.com/tags/">
                            <i class="fa fa-list">&nbsp;</i>Article List
                    </a>
                </li>
            
        </ul>
    </nav>
    <nav class="main">
        <ul>
            
            <li id="share-nav" class="share-menu" style="display:none;">
                <a class="fa-share-alt" href="#share-menu">Share</a>
            </li>
            
            <li class="search">
                <a class="fa-search" href="#search">Search</a>
                <form id="search" method="get" action="//google.com/search">
                    <input type="text" name="q" placeholder="Search" />
                    <input type="hidden" name="as_sitesearch" value="https://algotech.netlify.com/">
                </form>
            </li>
            <li class="menu">
                <a class="fa-bars" href="#menu">Menu</a>
            </li>
        </ul>
    </nav>
</header>


<section id="menu">

    
        <section>
            <form class="search" method="get" action="//google.com/search">
                <input type="text" name="q" placeholder="Search" />
                <input type="hidden" name="as_sitesearch" value="https://algotech.netlify.com/">
            </form>
        </section>

    
        <section>
            <ul class="links">
                
                    <li>
                        <a href="https://algotech.netlify.com/">
                            <h3>
                                <i class="fa fa-home">&nbsp;</i>Home
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="https://algotech.netlify.com/tags/machine-learning/">
                            <h3>
                                <i class="fa fa-cog">&nbsp;</i>Machine Learning
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="https://algotech.netlify.com/tags/data-visualization/">
                            <h3>
                                <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="https://algotech.netlify.com/tags/">
                            <h3>
                                <i class="fa fa-list">&nbsp;</i>Article List
                            </h3>
                        </a>
                    </li>
                
            </ul>
        </section>

    
        <section class="recent-posts">
            <div class="mini-posts">
                <header>
                    <h3>Recent Posts</h3>
                </header>
                

                
                    
                

                
                        <article class="mini-post">
                            <header>
                                <h3><a href="https://algotech.netlify.com/blog/regression-arima-arimax/">Regression ARIMA (ARIMAX)</a></h3>
                                
                                <time class="published" datetime=
                                    '2021-09-09'>
                                    September 9, 2021</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="https://algotech.netlify.com/blog/hotel-forecast/">Multiple Hotel Segments Demand Forecasting</a></h3>
                                
                                <time class="published" datetime=
                                    '2021-07-30'>
                                    July 30, 2021</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="https://algotech.netlify.com/blog/advancing-your-shinyapp-ii/">Advancing Your Shiny Application II</a></h3>
                                
                                <time class="published" datetime=
                                    '2021-06-03'>
                                    June 3, 2021</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="https://algotech.netlify.com/blog/gridsearchcv/">GridSearchCV</a></h3>
                                
                                <time class="published" datetime=
                                    '2021-05-22'>
                                    May 22, 2021</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="https://algotech.netlify.com/blog/kemiripan-teks/">Pengenalan Kemiripan Teks (Text Similarity) di Python</a></h3>
                                
                                <time class="published" datetime=
                                    '2021-05-20'>
                                    May 20, 2021</time>
                            </header>
                            

                        </article>
                

                
                    <a href=
                        
                            /blog/
                        
                        class="button">View more posts</a>
                
            </div>
        </section>

    
        
</section>

    <section id="share-menu">
    <section id="social-share-nav">
        <ul class="links">
            <header>
                <h3>Share this post <i class="fa fa-smile-o"></i></h3>
            </header>
            



<li>
  <a href="https://twitter.com/intent/tweet?text=Song2Vec%3a%20Music%20Recommender by Tomy%20Tjandra&amp;url=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f&amp;title=Song2Vec%3a%20Music%20Recommender" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











        </ul>
    </section>
</section>

    
    <div id="main">
        
        
        <article class="post">
  <header>
    <div class="title">
        
            <h2><a href="https://algotech.netlify.com/blog/song2vec-music-recommender/">Song2Vec: Music Recommender</a></h2>
        
        
    </div>
    <div class="meta">
        

        <time class="published"
            datetime='2020-06-29'>
            June 29, 2020</time>
        <span class="author"><a href="https://github.com/tomytjandra">Tomy Tjandra</a></span>
        
            <p>24 minute read</p>
        
        
    </div>
</header>


  
    <section id="social-share">
      <ul class="icons">
        



<li>
  <a href="https://twitter.com/intent/tweet?text=Song2Vec%3a%20Music%20Recommender by Tomy%20Tjandra&amp;url=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2falgotech.netlify.com%2fblog%2fsong2vec-music-recommender%2f&amp;title=Song2Vec%3a%20Music%20Recommender" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











      </ul>
    </section>
  

  

  <div id="content">
    


<style>
body {
text-align: justify}
</style>
<div id="background" class="section level1">
<h1>Background</h1>
<p>The behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music,
Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically.</p>
<p>Users may not have enough time to scan through all available songs and manually create a playlist. Instead, a recommender system is constructed which eases them to find relevant songs quickly. One example you might seen before is the “Made For You” feature from Spotify:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/made-for-you.png" style="width:80.0%" />
</center>
<p>These personalized playlists are being recommended by grouping similar songs that go well together. How? In the real case, this process is done by combining several recommender algorithms, simply based on users’ activities such as likes, playlist history, or even listening history. In this article, we will demonstrate how to extract song embeddings using a neural network approach specifically <strong>Word2Vec</strong> model, use it to generate songs recommendation, and evaluate the performance.</p>
<p>Okay, so you might wonder what is Word2Vec actually? Developed by Tomas Mikolov <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> in 2013 at Google, it is one of the most common technique to do word embeddings in several Natural Language Processing (NLP) cases using shallow neural network. Word embeddings is just a fancy way of saying a numerical representation of words. A good analogy would be how colors are represented with a RGB values. These set of values is then called as a <strong>vector</strong>. For example, “black” can be associated with (0,0,0) and “white” with (255,255,255) as their pixel intensity values.</p>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-3-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>In fact, word embeddings method can be generalized into other item embeddings, which associate any product on an e-commerce website, any videos on Youtube, movies on Netflix with a vector. Of course, in this case, songs can also be a vector.</p>
<p>Can you guess what is the property of a sentence that Word2Vec exploits to learn the vector representation of a word? It is the <strong>sequential nature of the text</strong>. Take a look of the following scrambled sentence:</p>
<blockquote>
<p><em>gives Spotify millions you access music service to digital a that is of songs.</em></p>
</blockquote>
<p>It is difficult for us to understand the text because there is no sequence in the sentence. That’s why the sequence of words is crucial in any natural language. This property can be implemented to other data that has sequential nature as well. One such data that has the property is <strong>playlist of songs</strong> in music streaming services. The following image is an example of playlists in Spotify, where each playlist contain a sequence of songs:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/playlist-menu.png" style="width:80.0%" />
</center>
<p>Since the data cleansing and modelling process will be quite complicated, here I present the visualization for you to understand the overall workflow for this article:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/workflow.png" style="width:100.0%" />
</center>
</div>
<div id="import-libraries" class="section level1">
<h1>Import Libraries</h1>
<p>Before going any further, let’s import necessary libraries such as:</p>
<ul>
<li><code>pandas</code> for data analysis</li>
<li><code>numpy</code> for scientific computing</li>
<li><code>matplotlib</code> and <code>seaborn</code> for data visualization</li>
<li><code>gensim</code> for topic modelling, in this case Word2vec</li>
<li><code>sklearn</code> and <code>spherecluster</code> for other unsupervised learning algorithm</li>
</ul>
<pre class="python"><code># Data Analysis
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
plt.style.use(&#39;seaborn&#39;)
sns.set_style(&quot;whitegrid&quot;)

# Modelling
from gensim.models import Word2Vec
from gensim.models.callbacks import CallbackAny2Vec
from spherecluster import SphericalKMeans
from sklearn.model_selection import train_test_split
from sklearn.manifold import TSNE
from scipy import stats

# Additional
import math
import random
import itertools
import multiprocessing
from tqdm import tqdm
from time import time
import logging
import pickle</code></pre>
</div>
<div id="data-cleansing" class="section level1">
<h1>Data Cleansing</h1>
<p>Human-made music playlists collected by Shuo Chen <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> from Cornell University are used to learn the song embeddings. The dataset contains US radio playlists from Yes.com and songs tag from Last.fm since December 2010 to May 2011. Each playlist will be treated as a sentence and each song in the playlist will be treated as one word.</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/list-illustration.png" style="width:80.0%" />
</center>
<p>The raw data consists of five separate txt files as follow:</p>
<ol style="list-style-type: decimal">
<li><code>song_hash.txt</code>: mapping from integer <code>song_id</code> to song’s <code>title</code> and <code>artist</code> name</li>
<li><code>tags.txt</code>: social tags, using integer <code>song_id</code> to represent a song</li>
<li><code>tag_hash.txt</code>: mapping from integer id to tag’s name</li>
<li><code>train.txt</code> and <code>test.txt</code>: playlists using integer <code>song_id</code> to represent a song</li>
</ol>
<div id="songs" class="section level2">
<h2>Songs</h2>
<p>Each song has its own <code>song_id</code> which maps to exactly one <code>title</code> and <code>artist</code> name. There are 75252 unique songs present in <code>song_hash.txt</code>.</p>
<pre class="python"><code>songs = pd.read_csv(FOLDER_PATH+&quot;song_hash.txt&quot;, sep = &#39;\t&#39;, header = None,
                    names = [&#39;song_id&#39;, &#39;title&#39;, &#39;artist&#39;], index_col = 0)
songs[&#39;artist - title&#39;] = songs[&#39;artist&#39;] + &quot; - &quot; + songs[&#39;title&#39;]
songs</code></pre>
<pre><code>#&gt;                                                      title  ...                                     artist - title
#&gt; song_id                                                     ...                                                   
#&gt; 0                             Gucci Time (w\/ Swizz Beatz)  ...          Gucci Mane - Gucci Time (w\/ Swizz Beatz)
#&gt; 1        Aston Martin Music (w\/ Drake &amp; Chrisette Mich...  ...  Rick Ross - Aston Martin Music (w\/ Drake &amp; Ch...
#&gt; 2                            Get Back Up (w\/ Chris Brown)  ...               T.I. - Get Back Up (w\/ Chris Brown)
#&gt; 3                       Hot Toddy (w\/ Jay-Z &amp; Ester Dean)  ...         Usher - Hot Toddy (w\/ Jay-Z &amp; Ester Dean)
#&gt; 4                                             Whip My Hair  ...                              Willow - Whip My Hair
#&gt; ...                                                    ...  ...                                                ...
#&gt; 75257                               Dearest (I&#39;m So Sorry)  ...         Picture Me Broken - Dearest (I&#39;m So Sorry)
#&gt; 75258                                            USA Today  ...                           Alan Jackson - USA Today
#&gt; 75259                                            Superstar  ...                              Raul Malo - Superstar
#&gt; 75260                                  Romancin&#39; The Blues  ...                Giacomo Gates - Romancin&#39; The Blues
#&gt; 75261                                         Inner Change  ...                     The Jazzmasters - Inner Change
#&gt; 
#&gt; [75262 rows x 3 columns]</code></pre>
</div>
<div id="tags" class="section level2">
<h2>Tags</h2>
<p>Each song has several tags that exist in <code>tags.txt</code> and the mapping is provided in <code>tag_hash.txt</code>.</p>
<pre class="python"><code>def readTXT(filename, start_line=0, sep=None):
    with open(FOLDER_PATH+filename) as file:
        return [line.rstrip().split(sep) for line in file.readlines()[start_line:]]</code></pre>
<pre class="python"><code>tags = readTXT(&quot;tags.txt&quot;)
tags[7:12]</code></pre>
<pre><code>#&gt; [[&#39;49&#39;, &#39;65&#39;, &#39;72&#39;, &#39;141&#39;, &#39;197&#39;], [&#39;11&#39;, &#39;35&#39;, &#39;154&#39;], [&#39;#&#39;], [&#39;#&#39;], [&#39;#&#39;]]</code></pre>
<p>If a song does not have any tag, it is indicated with just a ‘#’ as seen above. Replace it with the string “unknown” instead.</p>
<pre class="python"><code>mapping_tags = dict(readTXT(&quot;tag_hash.txt&quot;, sep = &#39;, &#39;))
mapping_tags[&#39;#&#39;] = &quot;unknown&quot;</code></pre>
<p>The <code>song_tags</code> dataframe is combined and merged with previous <code>songs</code>.</p>
<pre class="python"><code>song_tags = pd.DataFrame({&#39;tag_names&#39;: [list(map(lambda x: mapping_tags.get(x), t)) for t in tags]})
song_tags.index.name = &#39;song_id&#39;
songs = pd.merge(left = songs, right = song_tags, how = &#39;left&#39;,
                 left_index = True, right_index = True)
songs.index = songs.index.astype(&#39;str&#39;)
songs.head()</code></pre>
<pre><code>#&gt;                                                      title  ...                                          tag_names
#&gt; song_id                                                     ...                                                   
#&gt; 0                             Gucci Time (w\/ Swizz Beatz)  ...                                          [wjlb-fm]
#&gt; 1        Aston Martin Music (w\/ Drake &amp; Chrisette Mich...  ...  [chill, rnb, loved, hip hop, rap, soft, wjlb-f...
#&gt; 2                            Get Back Up (w\/ Chris Brown)  ...                                          [wjlb-fm]
#&gt; 3                       Hot Toddy (w\/ Jay-Z &amp; Ester Dean)  ...                                     [pop, hip-hop]
#&gt; 4                                             Whip My Hair  ...  [pop, american, dance, rnb, hip-hop, hip hop, ...
#&gt; 
#&gt; [5 rows x 4 columns]</code></pre>
</div>
<div id="unknown-songs" class="section level2">
<h2>Unknown Songs</h2>
<p>Unknown songs are defined as a song that doesn’t have either <code>artist</code> or <code>title</code>, indicated by dash (-) character. Remove these unknown songs from <code>songs</code>.</p>
<pre class="python"><code>unknown_songs = songs[(songs[&#39;artist&#39;] == &#39;-&#39;) | (songs[&#39;title&#39;] == &#39;-&#39;)]
songs.drop(unknown_songs.index, inplace = True)</code></pre>
</div>
<div id="playlist" class="section level2">
<h2>Playlist</h2>
<p><code>playlist</code> is a list of lists of songs (represented with its <code>song_id</code>) from <code>train.txt</code> and <code>test.txt</code>. There are 15910 playlists that exist in the data.</p>
<pre class="python"><code>playlist = readTXT(&quot;train.txt&quot;, start_line = 2) + readTXT(&quot;test.txt&quot;, start_line = 2)
print(f&quot;Playlist Count: {len(playlist)}&quot;)</code></pre>
<pre><code>#&gt; Playlist Count: 15910</code></pre>
<p>Take a look at how the playlist is represented in a list. Recall that these playlists are treated as sentences and the <code>song_id</code> as a token of words.</p>
<pre class="python"><code>for i in range(0, 2):
    print(&quot;-------------------------&quot;)
    print(f&quot;Playlist Idx. {i}: {len(playlist[i])} Songs&quot;)
    print(&quot;-------------------------&quot;)
    print(playlist[i])</code></pre>
<pre><code>#&gt; -------------------------
#&gt; Playlist Idx. 0: 97 Songs
#&gt; -------------------------
#&gt; [&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;, &#39;11&#39;, &#39;12&#39;, &#39;13&#39;, &#39;14&#39;, &#39;15&#39;, &#39;16&#39;, &#39;17&#39;, &#39;18&#39;, &#39;19&#39;, &#39;20&#39;, &#39;21&#39;, &#39;22&#39;, &#39;23&#39;, &#39;24&#39;, &#39;25&#39;, &#39;26&#39;, &#39;27&#39;, &#39;28&#39;, &#39;29&#39;, &#39;30&#39;, &#39;31&#39;, &#39;32&#39;, &#39;33&#39;, &#39;34&#39;, &#39;35&#39;, &#39;36&#39;, &#39;37&#39;, &#39;38&#39;, &#39;39&#39;, &#39;40&#39;, &#39;41&#39;, &#39;2&#39;, &#39;42&#39;, &#39;43&#39;, &#39;44&#39;, &#39;45&#39;, &#39;46&#39;, &#39;47&#39;, &#39;48&#39;, &#39;20&#39;, &#39;49&#39;, &#39;8&#39;, &#39;50&#39;, &#39;51&#39;, &#39;52&#39;, &#39;53&#39;, &#39;54&#39;, &#39;55&#39;, &#39;56&#39;, &#39;57&#39;, &#39;25&#39;, &#39;58&#39;, &#39;59&#39;, &#39;60&#39;, &#39;61&#39;, &#39;62&#39;, &#39;3&#39;, &#39;63&#39;, &#39;64&#39;, &#39;65&#39;, &#39;66&#39;, &#39;46&#39;, &#39;47&#39;, &#39;67&#39;, &#39;2&#39;, &#39;48&#39;, &#39;68&#39;, &#39;69&#39;, &#39;70&#39;, &#39;57&#39;, &#39;50&#39;, &#39;71&#39;, &#39;72&#39;, &#39;53&#39;, &#39;73&#39;, &#39;25&#39;, &#39;74&#39;, &#39;59&#39;, &#39;20&#39;, &#39;46&#39;, &#39;75&#39;, &#39;76&#39;, &#39;77&#39;, &#39;59&#39;, &#39;20&#39;, &#39;43&#39;]
#&gt; -------------------------
#&gt; Playlist Idx. 1: 205 Songs
#&gt; -------------------------
#&gt; [&#39;78&#39;, &#39;79&#39;, &#39;80&#39;, &#39;3&#39;, &#39;62&#39;, &#39;81&#39;, &#39;14&#39;, &#39;82&#39;, &#39;48&#39;, &#39;83&#39;, &#39;84&#39;, &#39;17&#39;, &#39;85&#39;, &#39;86&#39;, &#39;87&#39;, &#39;88&#39;, &#39;74&#39;, &#39;89&#39;, &#39;90&#39;, &#39;91&#39;, &#39;4&#39;, &#39;73&#39;, &#39;62&#39;, &#39;92&#39;, &#39;17&#39;, &#39;53&#39;, &#39;59&#39;, &#39;93&#39;, &#39;94&#39;, &#39;51&#39;, &#39;50&#39;, &#39;27&#39;, &#39;95&#39;, &#39;48&#39;, &#39;96&#39;, &#39;97&#39;, &#39;98&#39;, &#39;99&#39;, &#39;100&#39;, &#39;57&#39;, &#39;101&#39;, &#39;102&#39;, &#39;25&#39;, &#39;103&#39;, &#39;3&#39;, &#39;104&#39;, &#39;105&#39;, &#39;106&#39;, &#39;107&#39;, &#39;47&#39;, &#39;108&#39;, &#39;109&#39;, &#39;110&#39;, &#39;111&#39;, &#39;112&#39;, &#39;113&#39;, &#39;25&#39;, &#39;63&#39;, &#39;62&#39;, &#39;114&#39;, &#39;115&#39;, &#39;84&#39;, &#39;116&#39;, &#39;117&#39;, &#39;118&#39;, &#39;119&#39;, &#39;120&#39;, &#39;121&#39;, &#39;122&#39;, &#39;123&#39;, &#39;50&#39;, &#39;70&#39;, &#39;71&#39;, &#39;124&#39;, &#39;17&#39;, &#39;85&#39;, &#39;14&#39;, &#39;82&#39;, &#39;48&#39;, &#39;125&#39;, &#39;47&#39;, &#39;46&#39;, &#39;72&#39;, &#39;53&#39;, &#39;25&#39;, &#39;73&#39;, &#39;4&#39;, &#39;126&#39;, &#39;59&#39;, &#39;74&#39;, &#39;20&#39;, &#39;43&#39;, &#39;127&#39;, &#39;128&#39;, &#39;129&#39;, &#39;13&#39;, &#39;82&#39;, &#39;48&#39;, &#39;130&#39;, &#39;131&#39;, &#39;132&#39;, &#39;133&#39;, &#39;134&#39;, &#39;135&#39;, &#39;136&#39;, &#39;137&#39;, &#39;59&#39;, &#39;46&#39;, &#39;138&#39;, &#39;43&#39;, &#39;20&#39;, &#39;139&#39;, &#39;140&#39;, &#39;73&#39;, &#39;57&#39;, &#39;70&#39;, &#39;141&#39;, &#39;3&#39;, &#39;1&#39;, &#39;74&#39;, &#39;142&#39;, &#39;143&#39;, &#39;144&#39;, &#39;145&#39;, &#39;48&#39;, &#39;13&#39;, &#39;25&#39;, &#39;146&#39;, &#39;50&#39;, &#39;147&#39;, &#39;126&#39;, &#39;59&#39;, &#39;20&#39;, &#39;148&#39;, &#39;149&#39;, &#39;150&#39;, &#39;151&#39;, &#39;152&#39;, &#39;56&#39;, &#39;153&#39;, &#39;154&#39;, &#39;155&#39;, &#39;156&#39;, &#39;157&#39;, &#39;158&#39;, &#39;159&#39;, &#39;160&#39;, &#39;161&#39;, &#39;162&#39;, &#39;163&#39;, &#39;164&#39;, &#39;165&#39;, &#39;166&#39;, &#39;167&#39;, &#39;168&#39;, &#39;169&#39;, &#39;170&#39;, &#39;171&#39;, &#39;172&#39;, &#39;173&#39;, &#39;174&#39;, &#39;175&#39;, &#39;60&#39;, &#39;176&#39;, &#39;51&#39;, &#39;177&#39;, &#39;178&#39;, &#39;179&#39;, &#39;180&#39;, &#39;181&#39;, &#39;182&#39;, &#39;183&#39;, &#39;184&#39;, &#39;185&#39;, &#39;57&#39;, &#39;186&#39;, &#39;187&#39;, &#39;188&#39;, &#39;189&#39;, &#39;190&#39;, &#39;191&#39;, &#39;46&#39;, &#39;192&#39;, &#39;193&#39;, &#39;194&#39;, &#39;195&#39;, &#39;196&#39;, &#39;197&#39;, &#39;198&#39;, &#39;25&#39;, &#39;199&#39;, &#39;200&#39;, &#39;49&#39;, &#39;201&#39;, &#39;100&#39;, &#39;202&#39;, &#39;203&#39;, &#39;204&#39;, &#39;205&#39;, &#39;206&#39;, &#39;207&#39;, &#39;32&#39;, &#39;208&#39;, &#39;209&#39;, &#39;210&#39;]</code></pre>
<p>Remove unknown songs from the playlist.</p>
<pre class="python"><code>playlist_wo_unknown = [[song_id for song_id in p if song_id not in unknown_songs.index]
                       for p in playlist]</code></pre>
<p>Remove playlist with zero or one song, since the model wouldn’t capture any sequence in that list.</p>
<pre class="python"><code>clean_playlist = [p for p in playlist_wo_unknown if len(p) &gt; 1]
print(f&quot;Playlist Count After Cleansing: {len(clean_playlist)}&quot;)</code></pre>
<pre><code>#&gt; Playlist Count After Cleansing: 15842</code></pre>
<p>Remove song that doesn’t exist in any playlist.</p>
<pre class="python"><code>unique_songs = set(itertools.chain.from_iterable(clean_playlist))
song_id_not_exist = set(songs.index) - unique_songs
songs.drop(song_id_not_exist, inplace = True)
print(f&quot;Unique Songs After Cleansing: {songs.shape[0]}&quot;)</code></pre>
<pre><code>#&gt; Unique Songs After Cleansing: 73448</code></pre>
<p>Before there are 75262 unique songs and 15910 playlists. Now we are ready with 73448 unique songs and 15842 playlists.</p>
</div>
</div>
<div id="modelling" class="section level1">
<h1>Modelling</h1>
<p>The <code>playlist</code> is splitted into <code>playlist_train</code> and <code>playlist_test</code> with test size of 1000 playlist for further evaluation.</p>
<pre class="python"><code>playlist_train, playlist_test = train_test_split(clean_playlist, test_size = 1000,
                                                 shuffle = True, random_state = 123)</code></pre>
<div id="song2vec" class="section level2">
<h2>Song2Vec</h2>
<p>As mentioned before, Word2Vec is one of the most popular techniques to learn word embeddings using <strong>shallow neural network</strong>. A neural network, like other supervised learning algorithms, requires labeled data to be trained. How can we train a neural network if the data is in a form of sequences of words (i.e. words) or sequences of songs (i.e. playlist) without any target or data label? The network will be trained by creating a so-called <strong>“fake” task</strong>. We won’t be interested in the inputs and outputs of the network, rather just train the <strong>weights between input and hidden layer</strong> that are extracted as the vectors. To put it in simple terms, the goal of embeddings can be classified as unsupervised learning, but the process of getting the embeddings in Word2Vec is achieved by supervised learning through a neural network.</p>
<p>Here is the illustration of general Word2Vec architecture by Xin Rong <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/word2vec-architecture.png" style="width:80.0%" />
</center>
<p>Details:</p>
<ul>
<li>The input layer is a one-hot-encoded vector of size <span class="math inline">\(V\)</span> (vocabulary size).</li>
<li><span class="math inline">\(W_{V \times N}\)</span> is the weight matrix that projects the input <span class="math inline">\(x\)</span> to the hidden layer. <strong>These values are the embedded vectors</strong>.</li>
<li>The hidden layer contains <span class="math inline">\(N\)</span> neurons (hyperparameter), it just copies the weighted sum of inputs to the next layer without any activation function.</li>
<li><span class="math inline">\(W&#39;_{N \times V}\)</span> is the weight matrix that maps the hidden layer outputs to the final output layer.</li>
<li>The output layer is again a <span class="math inline">\(V\)</span> length vector, with a softmax activation function.</li>
</ul>
<p>There are two approaches of Word2Vec in which both are using the same architecture:</p>
<ul>
<li>Skip-gram - the fake task would be: given a target word, the model is trying to predict the context words.</li>
<li>Continuous Bag-Of-Words (CBOW) - the fake task would be: predict the target word by the context words.</li>
</ul>
<p>In this article, <strong>CBOW</strong> is used instead of Skip-gram, because according to Google Code Archive <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, it trains faster and able to capture the frequent songs more.</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/playlist-example.png" style="width:80.0%" />
</center>
<p>Target song that are played between context songs is assumed to be similar to each other. If the playlist are designed by users or the services for certain genre, the song embeddings will logically incorporate more information about the genre.</p>
<p>One epoch of CBOW may be breakdown into these steps <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/cbow.png" style="width:60.0%" />
</center>
<ol style="list-style-type: decimal">
<li>Convert the generated training samples into one-hot vectors <span class="math inline">\(x_1, x_2, ..., x_C\)</span> (contexts) for the input layer. So, the size is <span class="math inline">\(C \times V\)</span></li>
<li>Multiply all vector <span class="math inline">\(x\)</span> with <span class="math inline">\(W_{V \times N}\)</span> and then take the sum or mean of embedded vectors.</li>
<li>The hidden layer is then multiplied with <span class="math inline">\(W&#39;_{N \times V}\)</span> to get the weighted sum of size <span class="math inline">\(V\)</span>.</li>
<li>Apply softmax function to turn the weighted sum into probabilities, usually denoted by <span class="math inline">\(\hat{y}\)</span>.</li>
<li>Error between output and each context word is calculated as follows: <span class="math inline">\({(\hat{y} - y)}\)</span></li>
<li>Backpropagate to re-adjust the weights, by using Gradient Descent optimizer. <br>
<ol style="list-style-type: lower-alpha">
<li>All weights in output matrix will be updated. <br></li>
<li>Only corresponding word vector in the input matrix that will be updated.</li>
</ol></li>
</ol>
<p>Up until this point, you should have understood the general overview of how the Word2Vec works. But, there is an issue with the softmax function — it is <strong>computationally very expensive</strong>, as it requires scanning through the entire output embeddings matrix to compute the probability distribution of all V words, where V can be millions or more. The softmax function is defined as:</p>
<center>
<span class="math inline">\(softmax(y_i) = \dfrac{e^{y_i}}{\sum \limits_{y=1}^V e^{y_j}}\)</span>
</center>
<p>The normalization factor in the denominator also requires <span class="math inline">\(V\)</span> iterations. When implemented in codes, the normalization factor is computed only once and cached as a Python variable, making the algorithm complexity <span class="math inline">\(O(V)\)</span>.</p>
<p>Due to this computational inefficiency, softmax function is preferably not used in most implementations of Word2Vec. Instead let’s use an alternative called <strong>negative sampling</strong> with sigmoid function, which rephrases the problem into a set of independent binary logistic classification task of algorithm complexity = <span class="math inline">\(O(K+1)\)</span>, where <span class="math inline">\(K\)</span> is the number of negative samples and <span class="math inline">\(1\)</span> is the positive sample. Mikolov suggests using <span class="math inline">\(K\)</span> in the range <span class="math inline">\([5, 20]\)</span> for small vocabulary and <span class="math inline">\([2, 5]\)</span> for a larger vocabulary.</p>
<p>Don’t worry about the code below. We are setting up the logging settings to monitor the training process.</p>
<pre class="python"><code>logging.basicConfig(format=&quot;%(asctime)s : %(levelname)s : %(message)s&quot;, level=logging.INFO)

class Callback(CallbackAny2Vec):
    def __init__(self):
        self.epoch = 1
        self.training_loss = []

    def on_epoch_end(self, model):
        loss = model.get_latest_training_loss()
        if self.epoch == 1:
            current_loss = loss
        else:
            current_loss = loss - self.loss_previous_step
        print(f&quot;Loss after epoch {self.epoch}: {current_loss}&quot;)
        self.training_loss.append(current_loss)
        self.epoch += 1
        self.loss_previous_step = loss</code></pre>
<div id="training" class="section level3">
<h3>Training</h3>
<p>By using <code>gensim</code>, the training process can be separated into <strong>three distinctive steps</strong> <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>:</p>
<p>First, the instance of <code>Word2Vec()</code> is created to set up the parameters of the model and leave the model uninitialized.</p>
<ul>
<li><code>size</code>: dimensionality of the song vectors</li>
<li><code>window</code>: maximum distance between context and target</li>
<li><code>min_count</code>: frequency cut-off for a song to be considered in the model</li>
<li><code>sg = 0</code>: using CBOW architecture</li>
<li><code>negative</code>: negative sampling data</li>
<li><code>workers</code>: number of CPU used to train the model</li>
</ul>
<pre class="python"><code>model = Word2Vec(
    size = 256,
    window = 10,
    min_count = 1,
    sg = 0,
    negative = 20,
    workers = multiprocessing.cpu_count()-1)
print(model)</code></pre>
<pre><code>#&gt; Word2Vec(vocab=0, size=256, alpha=0.025)</code></pre>
<p>Secondly, the method <code>.build_vocab()</code> is called to build the vocabulary from a sequence of playlists and thus initialized the model.</p>
<pre class="python"><code>logging.disable(logging.NOTSET) # enable logging
t = time()

model.build_vocab(playlist_train)</code></pre>
<pre><code>#&gt; 2020-06-29 14:35:46,001 : INFO : collecting all words and their counts
#&gt; 2020-06-29 14:35:46,001 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
#&gt; 2020-06-29 14:35:46,211 : INFO : PROGRESS: at sentence #10000, processed 1805894 words, keeping 63337 word types
#&gt; 2020-06-29 14:35:46,338 : INFO : collected 72047 word types from a corpus of 2670082 raw words and 14842 sentences
#&gt; 2020-06-29 14:35:46,338 : INFO : Loading a fresh vocabulary
#&gt; 2020-06-29 14:35:46,562 : INFO : effective_min_count=1 retains 72047 unique words (100% of original 72047, drops 0)
#&gt; 2020-06-29 14:35:46,562 : INFO : effective_min_count=1 leaves 2670082 word corpus (100% of original 2670082, drops 0)
#&gt; 2020-06-29 14:35:46,726 : INFO : deleting the raw counts dictionary of 72047 items
#&gt; 2020-06-29 14:35:46,728 : INFO : sample=0.001 downsamples 3 most-common words
#&gt; 2020-06-29 14:35:46,728 : INFO : downsampling leaves estimated 2667923 word corpus (99.9% of prior 2670082)
#&gt; 2020-06-29 14:35:46,872 : INFO : estimated required memory for 72047 words and 256 dimensions: 183575756 bytes
#&gt; 2020-06-29 14:35:46,873 : INFO : resetting layer weights</code></pre>
<p>Finally, <code>.train()</code> trains the model. The loggings here are mainly useful for monitoring the loss after each epoch.</p>
<ul>
<li><code>total_examples</code>: count of unique vocabulary (songs)</li>
<li><code>epochs</code>: number of iterations over the dataset (whole playlist)</li>
<li><code>compute_loss</code>: track model loss</li>
</ul>
<pre class="python"><code>logging.disable(logging.INFO) # disable logging
callback = Callback() # instead, print out loss for each epoch
t = time()

model.train(playlist_train,
            total_examples = model.corpus_count,
            epochs = 100,
            compute_loss = True,
            callbacks = [callback]) 

model.save(MODEL_PATH+&quot;song2vec.model&quot;)</code></pre>
<pre class="python"><code>print(model)</code></pre>
<pre><code>#&gt; Word2Vec(vocab=72047, size=256, alpha=0.025)</code></pre>
</div>
<div id="loss-evaluation" class="section level3">
<h3>Loss Evaluation</h3>
<p>Plot the training loss, making sure it decreases after each epoch. The closer the loss to a zero value, the better the model is in predicting a target song given surrounding context songs. Thus, the produced song vectors are more meaningful.</p>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-25-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="vectors-visualization" class="section level3">
<h3>Vectors Visualization</h3>
<p>The song vectors can be visualized using a gradient of colors. The model is trained using 256 dimensions, therefore there will be 256 color bars for each song, representing element values in the vector. The similarity between songs is calculated using <strong>cosine similarity</strong>:</p>
<center>
<span class="math inline">\(similarity(A,B) = cos(\theta) = \frac{A.B}{\|A\| \|B\|}\)</span>
</center>
<p>Mathematically it measures the cosine of the angle between two vectors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> which projected in a multi-dimensional space. Song vectors with similar context occupy close spatial positions; the cosine between such vectors should be close to 1, i.e. angle is closer to 0. The smaller the angle, the cosine similarity will be higher.</p>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-26-1.png" width="120%" style="display: block; margin: auto;" /></p>
<p>The plot above shows five most similar songs to <code>song_id = '4162'</code> (Maroon 5 - She Will Be Loved). Up until now, the model can be used for recommending new songs using cosine similarity, but only based on one main song.</p>
</div>
</div>
<div id="clustering" class="section level2">
<h2>Clustering</h2>
<p>What can we do with the song vectors? One thing is to group them into several clusters using K-Means clustering, but keep in mind that the similarity between vectors is calculated using cosine distance instead of regular (Euclidean) distance. Therefore K-Means with cosine distance should be considered, which often called <strong>Spherical K-Means Clustering</strong>. The idea is to identify the centroid such that it uniforms and minimizes the angle between each vector in a cluster. The intuition is just like looking at a cluster of stars where each point should have consistent spacing between each other. This spacing is referred to as the cosine similarity.</p>
<div id="spherical-k-means" class="section level3">
<h3>Spherical K-Means</h3>
<p>Take a look at the picture below for the illustration, and here are the steps:</p>
<ol style="list-style-type: decimal">
<li>Generate random 2D vectors ranging from (0,0) to (1,1).</li>
<li>Project each vector onto a unit circle, so that the vectors are normalized (length is equal to one).</li>
<li>From the projected vectors, perform basic k-means clustering into k clusters such that the vector within the same cluster are as similar as possible while the vector from different clusters is as dissimilar as possible.</li>
<li>Assign cluster number for each vector.</li>
</ol>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-27-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>That being said, let’s perform Spherical K-Means on the song vectors by iterating the number of clusters from 10 to 500 so that the optimal number of clusters <code>k_opt</code> can be chosen by the elbow method.</p>
<pre class="python"><code>embedding_matrix = model.wv[model.wv.vocab.keys()]
embedding_matrix.shape</code></pre>
<pre><code>#&gt; (72047, 256)</code></pre>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>How to locate the optimal number of clusters objectively? Here is the idea <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/elbow-method.png" style="width:60.0%" />
</center>
<ol style="list-style-type: decimal">
<li>Connect the first and last point of the curve with a straight line</li>
<li>Calculate the perpendicular distance from each point to that line</li>
<li>Consider the longest distance as the elbow</li>
</ol>
<pre class="python"><code>k_opt = locateOptimalElbow(skm_df.index, skm_df[&#39;WCSS&#39;].values)
skm_opt = skm_df.loc[k_opt, &quot;skm_object&quot;]
skm_opt</code></pre>
<pre><code>#&gt; SphericalKMeans(copy_x=True, init=&#39;k-means++&#39;, max_iter=300, n_clusters=110,
#&gt;         n_init=5, n_jobs=-1, normalize=True, random_state=123, tol=0.0001,
#&gt;         verbose=0)</code></pre>
<pre class="python"><code>songs_cluster = songs.copy()
songs_cluster.loc[model.wv.vocab.keys(), &#39;cluster&#39;] = skm_opt.labels_
songs_cluster[&#39;cluster&#39;] = songs_cluster[&#39;cluster&#39;].fillna(-1).astype(&#39;int&#39;).astype(&#39;category&#39;)
songs_cluster.head()</code></pre>
<pre><code>#&gt;                                                      title  ... cluster
#&gt; song_id                                                     ...        
#&gt; 0                             Gucci Time (w\/ Swizz Beatz)  ...      94
#&gt; 1        Aston Martin Music (w\/ Drake &amp; Chrisette Mich...  ...      94
#&gt; 2                            Get Back Up (w\/ Chris Brown)  ...      33
#&gt; 3                       Hot Toddy (w\/ Jay-Z &amp; Ester Dean)  ...      94
#&gt; 4                                             Whip My Hair  ...      94
#&gt; 
#&gt; [5 rows x 5 columns]</code></pre>
<p>In the end, the optimal number of clusters is set to be 110. There is a possibility that some songs don’t have the embedded vectors since the <code>playlist</code> is split to train and test. For this case, assign the cluster as -1 instead.</p>
</div>
<div id="visualize-clusters" class="section level3">
<h3>Visualize Clusters</h3>
<p>It is always quite helpful to visualize the embeddings that have been created. Over here, we have song vectors with 256 dimensions. These high-dimensional vectors can’t be visualized in our 3D world, so using dimensionality reduction algorithms such as <strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong> helps us map the vectors to a lower dimension. The mathematical detail of t-SNE will not be presented here, but in practice, it tends to produce a visualization with distinctly isolated clusters.</p>
<pre class="python"><code>embedding_tsne = TSNE(n_components = 2, metric = &#39;cosine&#39;,
                      random_state = 123).fit_transform(embedding_matrix)
                      
save2Pickle(embedding_tsne, &quot;tsne_viz&quot;)</code></pre>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The cluster might look cluttered since all 110 clusters are being plotted at once. Instead, let’s just perform t-SNE on randomly selected 10 clusters and visualize the result.</p>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-37-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Songs that have similar context (by cosine similarity) tend to be plotted next to each other. Thus, creating distinct song clusters. Note that the clusters might look overlap to each other due to the dimensionality reduction, but in the actual dimension, they do not.</p>
</div>
</div>
</div>
<div id="start-recommending" class="section level1">
<h1>Start Recommending</h1>
<p>Congratulations! We are finally ready with the embeddings for every song that exists in <code>playlist_train</code>. How these song vectors are then used to suggest similar songs based on a certain playlist? One way is to calculate a <strong>playlist vector</strong> for each playlist by averaging together all the song vectors in that playlist. These vectors then become the query to find similar songs based on cosine similarity. Here is an illustration using a users’ music streaming playlist <a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>:</p>
<center>
<img src="https://algotech.netlify.com/img/song2vec-music-recommender/playlist-vector.gif" style="width:80.0%" />
</center>
<p>For each playlist in <code>playlist_test</code>, calculate the average vectors using <code>meanVectors()</code> function. If the song hasn’t been embedded before, neglect the song instead.</p>
<pre class="python"><code>def meanVectors(playlist):
    vec = []
    for song_id in playlist:
        try:
            vec.append(model.wv[song_id])
        except KeyError:
            continue
    return np.mean(vec, axis=0)</code></pre>
<pre class="python"><code>playlist_vec = list(map(meanVectors, playlist_test))</code></pre>
<p>For each playlist vector, we can recommend top <span class="math inline">\(n\)</span> similar songs based on the cosine similarity. Let’s test the song embeddings to recommend top 10 songs for <code>playlist_test</code> in index <code>305</code>.</p>
<pre class="python"><code>def similarSongsByVector(vec, n = 10, by_name = True):
    # extract most similar songs for the input vector
    similar_songs = model.wv.similar_by_vector(vec, topn = n)
    
    # extract name and similarity score of the similar products
    if by_name:
        similar_songs = [(songs.loc[song_id, &quot;artist - title&quot;], sim)
                              for song_id, sim in similar_songs]
    
    return similar_songs</code></pre>
<pre class="python"><code>print_recommended_songs(idx = 305, n = 10)</code></pre>
<pre><code>#&gt; ============================
#&gt; SONGS PLAYLIST
#&gt; ============================
#&gt; Selena - Como La Flor
#&gt; The Texas Tornados - Who Were You Thinkin&#39; Of
#&gt; Selena - Sentimientos
#&gt; 
#&gt; ============================
#&gt; TOP 10 RECOMMENDED SONGS
#&gt; ============================
#&gt; [Similarity: 0.835] Selena - Como La Flor
#&gt; [Similarity: 0.779] Selena - Sentimientos
#&gt; [Similarity: 0.763] Little Joe Y La Familia - Borrachera
#&gt; [Similarity: 0.751] Lorenzo Antonio - Con La Misma Espina
#&gt; [Similarity: 0.745] Tierra Tejana - Eres Casado
#&gt; [Similarity: 0.742] Jennifer Y Los Jetz - Me Piden
#&gt; [Similarity: 0.730] The Texas Tornados - (Hey Baby) Que Paso
#&gt; [Similarity: 0.712] The Texas Tornados - Who Were You Thinkin&#39; Of
#&gt; [Similarity: 0.709] Ruben Vela - La Papaya
#&gt; [Similarity: 0.704] Sparx - Lo Dice Mi Corazon
#&gt; ============================</code></pre>
<p>Interestingly, the model is able to capture and recommend new songs based on the “Spanish” genre from <code>playlist_test</code> indexed at <code>305</code> without being explicitly stated. Great! The final step is to evaluate how this recommender performs.</p>
</div>
<div id="evaluation" class="section level1">
<h1>Evaluation</h1>
<p>One way to evaluate the performance of a recommender system is by computing <strong>hit rate</strong> as follows:</p>
<ol style="list-style-type: decimal">
<li>For each song in a playlist, intentionally <strong>Leave-One-Out (LOO)</strong> this song.</li>
<li>By using several systems below, try to guess the LOO song.</li>
<li>Ask the recommender for top <span class="math inline">\(n\)</span> recommended songs.</li>
<li>If the LOO song appears in the top <span class="math inline">\(n\)</span> recommendation, consider it as a <strong>HIT</strong>. Otherwise not.</li>
<li>Repeat the LOO process until the end of the playlist. Then, the hit rate of a playlist is calculated by dividing the number of HIT with the length of a playlist.</li>
<li>Repeat step 1-5 for all playlist in <code>playlist_test</code> and calculate the <strong>Average Hit Rate at <span class="math inline">\(n\)</span> (<a href="mailto:AHR@n" class="email">AHR@n</a>)</strong>.</li>
</ol>
<pre class="python"><code>top_n_songs = 25</code></pre>
<div id="random-recommender" class="section level2">
<h2>Random Recommender</h2>
<p>As a baseline, let’s try to guess the LOO song randomly without any system.</p>
<pre class="python"><code>def hitRateRandom(playlist, n_songs):
    hit = 0
    for i, target in enumerate(playlist):
        random.seed(i)
        recommended_songs = random.sample(list(songs.index), n_songs)
        hit += int(target in recommended_songs)
    return hit/len(playlist)</code></pre>
<pre class="python"><code>eval_random = pd.Series([hitRateRandom(p, n_songs = top_n_songs)
                         for p in tqdm(playlist_test, position=0, leave=True)])
eval_random.mean()</code></pre>
<blockquote>
<p>Output: 0.00030413731380910425</p>
</blockquote>
</div>
<div id="song-tags-recommender" class="section level2">
<h2>Song Tags Recommender</h2>
<p>It is possible to recommend based on song tags provided on the data as follows:</p>
<ol style="list-style-type: decimal">
<li>Create a list of song <code>tag_names</code> that surrounds the LOO song. The maximum distance between the LOO and context songs is defined by <code>window</code>.</li>
<li>List all possible songs from the list.</li>
<li>Take <span class="math inline">\(n\)</span> songs randomly from the possible songs list.</li>
</ol>
<pre class="python"><code>mapping_tag2song = songs.explode(&#39;tag_names&#39;).reset_index().groupby(&#39;tag_names&#39;)[&#39;song_id&#39;].apply(list)

def hitRateContextSongTag(playlist, window, n_songs):
    hit = 0
    context_target_list = [([playlist[w] for w in range(idx-window, idx+window+1)
                             if not(w &lt; 0 or w == idx or w &gt;= len(playlist))], target)
                           for idx, target in enumerate(playlist)]
    for i, (context, target) in enumerate(context_target_list):
        context_song_tags = set(songs.loc[context, &#39;tag_names&#39;].explode().values)
        possible_songs_id = set(mapping_tag2song[context_song_tags].explode().values)
        
        random.seed(i)
        recommended_songs = random.sample(possible_songs_id, n_songs)
        hit += int(target in recommended_songs)
    return hit/len(playlist)</code></pre>
<pre class="python"><code>eval_song_tag = pd.Series([hitRateContextSongTag(p, model.window, n_songs = top_n_songs)
                           for p in tqdm(playlist_test, position=0, leave=True)])
eval_song_tag.mean()</code></pre>
<blockquote>
<p>Output: 0.0005425495180688559</p>
</blockquote>
</div>
<div id="cluster-based-recommender" class="section level2">
<h2>Cluster-based Recommender</h2>
<p>To improve further, let’s utilize the result of clustering in the modelling section:</p>
<ol style="list-style-type: decimal">
<li>Identify which cluster number is the most frequent (by majority voting) in surrounding songs. The maximum distance between the LOO and context songs is defined by <code>window</code>.</li>
<li>List out possible songs from that majority cluster.</li>
<li>Take <span class="math inline">\(n\)</span> songs randomly from the possible songs list.</li>
</ol>
<pre class="python"><code>def hitRateClustering(playlist, window, n_songs):
    hit = 0
    context_target_list = [([playlist[w] for w in range(idx-window, idx+window+1)
                             if not(w &lt; 0 or w == idx or w &gt;= len(playlist))], target)
                           for idx, target in enumerate(playlist)]
    for context, target in context_target_list:
        cluster_numbers = skm_opt.predict([model.wv[c] for c in context if c in model.wv.vocab.keys()])
        majority_voting = stats.mode(cluster_numbers).mode[0]
        possible_songs_id = list(songs_cluster[songs_cluster[&#39;cluster&#39;] == majority_voting].index)
        recommended_songs = random.sample(possible_songs_id, n_songs)
        songs_id = list(zip(*recommended_songs))[0]
        hit += int(target in songs_id)
    return hit/len(playlist)</code></pre>
<pre class="python"><code>eval_clust = pd.Series([hitRateClustering(p, model.window, n_songs = top_n_songs)
                           for p in tqdm(playlist_test, position=0, leave=True)])
eval_clust.mean()</code></pre>
<blockquote>
<p>Output: 0.005054657281168753</p>
</blockquote>
</div>
<div id="song2vec-recommender" class="section level2">
<h2>Song2Vec Recommender</h2>
<p>Lastly, evaluate the CBOW Song2Vec model as follows:</p>
<ol style="list-style-type: decimal">
<li>Take the average vectors of surrounding context songs using previously defined <code>meanVectors()</code> function. The maximum distance is defined by <code>window</code>.</li>
<li>Find top <span class="math inline">\(n\)</span> similar songs based on cosine similarity using <code>similarSongsByVector()</code> function.</li>
</ol>
<pre class="python"><code>def hitRateSong2Vec(playlist, window, n_songs):
    hit = 0
    context_target_list = [([playlist[w] for w in range(idx-window, idx+window+1)
                             if not(w &lt; 0 or w == idx or w &gt;= len(playlist))], target)
                           for idx, target in enumerate(playlist)]
    for context, target in context_target_list:
        context_vector = meanVectors(context)
        recommended_songs = similarSongsByVector(context_vector, n = n_songs, by_name = False)
        songs_id = list(zip(*recommended_songs))[0]
        hit += int(target in songs_id)
    return hit/len(playlist)</code></pre>
<pre class="python"><code>eval_song2vec = pd.Series([hitRateSong2Vec(p, model.window, n_songs = top_n_songs)
                           for p in tqdm(playlist_test, position=0, leave=True)])
eval_song2vec.mean()</code></pre>
<blockquote>
<p>Output: 0.11958469298590102</p>
</blockquote>
</div>
<div id="comparison" class="section level2">
<h2>Comparison</h2>
<p>Finally, we compare the calculated Average Hit Rate at 25 (<a href="mailto:AHR@25" class="email">AHR@25</a>) of the four recommender systems. The higher the AHR, the better is the system. From the bar plot below, Song2Vec outperforms other methods in terms of hit rate, which means that it can recommend a song well based on surrounding context songs. In a real-life scenario, this system may likely to be low quality since the AHR is only around 12%, but still, it is much better than no recommender system at all.</p>
<p><img src="https://algotech.netlify.com/blog/2020-06-29-song2vec-music-recommender_files/figure-html/unnamed-chunk-53-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>Song2Vec is an implementation of Word2Vec which able to capture the context of a song based on surrounding songs in a playlist. In this article, we successfully exploit the sequential property of a playlist and represent each song with a 256-dimensional vector. This vector representation is then used as a recommender system based on cosine similarity score. The objective of a music recommender is to create accurate personalized recommendations from historical playlist or listening queue. Therefore, metric such as <a href="mailto:AHR@n" class="email">AHR@n</a> is used to evaluate how many times (on average) a song is listed on the top-<span class="math inline">\(n\)</span> recommended songs based on surrounding context songs.</p>
<p>Things to be taken carefully when applying Song2Vec on its own is the <strong>cold start problem</strong>, a condition where it is impossible to recommend any songs to a new user or even recommend a new song to any users. This can be efficiently handled by combining the recommender using a content-based technique, which utilizes explicit features or characteristics of the songs as demonstrated in the “Song Tags Recommender” section.</p>
<p>Maybe you’re wondering what are other implementations of Word2Vec? Here is the list for you:</p>
<ul>
<li>Product recommendations: Using purchase receipts in a transaction to capture an item embeddings to learn the user’s purchase activity.</li>
<li>Listing recommendations: The user activity is in the form of click data, which can be represented as a sequence of listings that a user viewed.</li>
<li>Matching advertisement to search query: Data consist of sequential search sessions, including entered query, clicked advertisement, and search results.</li>
</ul>
<blockquote>
<p>The full Jupyter Notebook is available on my <a href="https://github.com/tomytjandra/song2vec-music-recommender">Github</a></p>
</blockquote>
</div>
<div id="annotation" class="section level1">
<h1>Annotation</h1>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://arxiv.org/pdf/1310.4546.pdf">Distributed Representations of Words and Phrases and their Compositionality</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="https://www.cs.cornell.edu/~shuochen/lme/data_page.html">Playlist Dataset</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="https://arxiv.org/pdf/1411.2738.pdf">word2vec Parameter Learning Explained</a><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://code.google.com/archive/p/word2vec/">word2vec:
Tool for computing continuous distributed representations of words</a><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p><a href="https://arxiv.org/pdf/1411.2738.pdf">word2vec Parameter Learning Explained</a><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p><a href="https://radimrehurek.com/gensim/">gensim: Topic modelling for humans</a><a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p><a href="https://www.researchgate.net/figure/Example-of-the-elbow-criterion-applied-over-the-curve-of-within-class-sum-of-squares-per_fig1_282000605">Fast Single- and Cross-Show Speaker Diarization Using Binary Key Speaker Modeling</a><a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p><a href="https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484">Using Word2Vec for Music Recommendations</a><a href="#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

  </div>

  <footer>
    <ul class="stats">
  <li class="categories">
    <ul>
        
            
            
                <i class="fa fa-folder"></i>
                
                
                <li><a class="article-category-link" href="https://algotech.netlify.com/categories/python">Python</a></li>
                
            
        
    </ul>
  </li>
  <li class="tags">
    <ul>
        
            
            
                <i class="fa fa-tags"></i>
                
                
                <li><a class="article-category-link" href="https://algotech.netlify.com/tags/machine-learning">Machine Learning</a></li>
                
                
                <li><a class="article-category-link" href="https://algotech.netlify.com/tags/topic-modelling">Topic Modelling</a></li>
                
                
                <li><a class="article-category-link" href="https://algotech.netlify.com/tags/recommender-system">Recommender System</a></li>
                
                
                <li><a class="article-category-link" href="https://algotech.netlify.com/tags/gensim">gensim</a></li>
                
            
        
    </ul>
  </li>
</ul>

  </footer>

</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-algotech-netlify-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>


<ul class="actions pagination">
    
        <li><a href="https://algotech.netlify.com/blog/regression-with-panel-data/"
                class="button big previous">Regression Model with Panel Data</a></li>
    

    
        <li><a href="https://algotech.netlify.com/blog/rplicate-happiness-of-the-third-age/"
                class="button big next">Rplicate Series: Happiness of The Third Age</a></li>
    
</ul>


    </div>
    
<section id="sidebar">

  
  <section id="intro">
    
    
      
        <a href='https://algotech.netlify.com/'><img src="https://algotech.netlify.com/img/main/logo.png" class="intro-circle" width="30%" alt="Hugo Future Imperfect" /></a>
      
    
    
      <header>
        <h2>Algoritma Technical Blog</h2>
        <p>We're a group of people who teach data science to individuals, trains companies and their employees to better profit from data. We care about the development of data science and a sense of community that connects our alumni and team with one another. To learn more about our approach to data science problems, feel free to hop over to our blog.</p>
      </header>
    
    
      <ul class="icons">
        
        
  <li><a href="//github.com/teamalgoritma" target="_blank" title="GitHub" class="fa fa-github"></a></li>



























  <li><a href="//linkedin.com/company/teamalgoritma" target="_blank" title="LinkedIn Company" class="fa fa-linkedin"></a></li>









  <li><a href="//facebook.com/teamalgoritma" target="_blank" title="Facebook" class="fa fa-facebook"></a></li>





















  <li><a href="//instagram.com/teamalgoritma" target="_blank" title="Instagram" class="fa fa-instagram"></a></li>





  <li><a href="//twitter.com/teamalgoritma" target="_blank" title="Twitter" class="fa fa-twitter"></a></li>




















      </ul>
    
  </section>

  
  <section class="recent-posts">
    <div class="mini-posts">
      <header>
        <h3>Upcoming Workshop</h3>
      </header>
      <div class="posts-container">
          <article class="mini-post">
            <header>
              
              <h3>
                <a href="https://algorit.ma/ds-course/hr-industry/?utm_source=algotech"><img src="https://algotech.netlify.com/img/2021/ads/ks-hr.png", alt="Building Tools for the HR Industry",  width="270" height="340">More details</a>
              </h3>
              
              <h3>
                <a href="https://algorit.ma/ds-course/dss-trading/?utm_source=algotech"><img src="https://algotech.netlify.com/img/2021/ads/dss_okt.png", alt="Building Algorithmic Trading Dashboard",  width="270" height="340">More details</a>
              </h3>
              
              <h3>
                <a href="https://algorit.ma/dds-oil-gas/?utm_source=algotech"><img src="https://algotech.netlify.com/img/2021/ads/dds-oilgas.png", alt="DDS: Secrets to a Successful Analytics Project in the Oil and Gas Industry",  width="270" height="340">More details</a>
              </h3>
            </header>
          </article>
      </div>

      
      
    </div>
  </section>

  
  
  

  
  

  
  <section id="footer">
    <p class="copyright">
      
        &copy; 2021
        
          Algoritma Technical Blog
        
      .
      Powered by <a href="//gohugo.io" target="_blank">Hugo</a>
    </p>
  </section>
</section>

    </div>
    <a id="back-to-top" href="#" class="fa fa-arrow-up fa-border fa-2x"></a>
    <style>
      .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        height:50px; 
        background-color: black;
        color: white;
        text-align: center;
        padding-top: 15px;
        padding-bottom: 15px;
        padding-left: 50px;
        padding-right: 50px;
}
      }


      </style>

      <div class="footer">
        <p>
          Want to know more about our workshop?
          <a href="https://algorit.ma/?utm_source=algotech&utm_medium=content&utm_campaign=song2vec-music-recommender" style="color: rgb(197, 38, 38)"> Visit our main website here</a> <br>
        </p>
          
      </div>
    

    
      
    

    
      
      
      
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>
        
        
        
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/css.min.js"></script>
        <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
      
    
    
    
      <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.js"></script>
      <script src="https://algotech.netlify.com/js/util.js"></script>
      <script src="https://algotech.netlify.com/js/main.js"></script>
      <script src="https://algotech.netlify.com/js/backToTop.js"></script>
    

    
      
        
      
        
          <script src="https://algotech.netlify.com/js/bootstrap.min.js"></script>
        
      
    

    
    <script>hljs.initHighlightingOnLoad();</script>
      <script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


  </body>
</html>

